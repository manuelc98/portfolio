{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf002c91-0d69-45eb-bf2b-26e48899c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import math \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer #Tokenizer that takes only alphanumerical characters (no punctuation)\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ca0d6776-6db6-437b-bdd8-eeddf51ae539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_french_review(review_text_object):\n",
    "    \"\"\"Takes a text review object as input\n",
    "    Returns the French version of the review only\"\"\"\n",
    "    if review_text_object[:8] == \"(Traduit\":\n",
    "        return review_text_object.replace(\"(Traduit par Google) \", \"\").replace(\"\\xa0\", \"\").split(\"(Avis d'origine)\")[0]\n",
    "    else:\n",
    "        return review_text_object.replace(\"(Traduit par Google) \", \"\").replace(\"\\xa0\", \"\")\n",
    "    \n",
    "    \n",
    "def find_nb_scroll(N):\n",
    "    \"\"\"Takes N an int, number of reviews that was left\n",
    "    Returns number of scrolls needed to load all reviews\"\"\"\n",
    "    if N%10 == 0:\n",
    "        return int(N/10 - 1)\n",
    "    else:\n",
    "        return math.floor(N/10)\n",
    "    \n",
    "    \n",
    "def get_review_summary(result_set):\n",
    "    \"\"\"Input: Text object, raw output of HTML data of the page\n",
    "    Output: Pandas dataframe with one line per review with rate, time and comment\"\"\"\n",
    "    rev_dict = {\n",
    "        'Review Rate': [],\n",
    "        'Review Time Amount' : [],\n",
    "        'Review Time Period' : [],\n",
    "        'Review Text' : []\n",
    "                }\n",
    "    for result in result_set:\n",
    "        try:\n",
    "            review_rate = int(result.find('span', class_='Fam1ne EBe2gf')[\"aria-label\"][7])\n",
    "        except:\n",
    "            review_rate = \"\"\n",
    "        try:\n",
    "            review_time_amount = int(result.find('span',class_='dehysf lTi8oc').text[7:].replace('\\xa0', ' ').replace('une', '1').replace('un', '1').split()[0])\n",
    "        except:\n",
    "            review_time_amount = \"\"\n",
    "        try:\n",
    "            review_time_period = result.find('span',class_='dehysf lTi8oc').text[7:].replace('\\xa0', ' ').replace('une', '1').split()[1]\n",
    "        except:\n",
    "            review_time_period = \"\"\n",
    "        try:\n",
    "            review_text = result.find('span',class_='review-full-text').text\n",
    "            review_text = take_french_review(review_text)\n",
    "        except:\n",
    "            review_text = \"\"\n",
    "        rev_dict['Review Rate'].append(review_rate)\n",
    "        rev_dict['Review Time Amount'].append(review_time_amount)\n",
    "        rev_dict['Review Time Period'].append(review_time_period)\n",
    "        rev_dict['Review Text'].append(review_text)\n",
    "    return(pd.DataFrame(rev_dict))\n",
    "\n",
    "\n",
    "# Function to concat strings\n",
    "def concat_strings(df):\n",
    "    sentence = ''\n",
    "    list_of_sentences = df[\"Review Text\"].tolist()\n",
    "    for string in list_of_sentences:\n",
    "        sentence = sentence + string\n",
    "    return sentence\n",
    "\n",
    "\n",
    "# Function to lemmatize\n",
    "def lemmatize(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    return [X.lemma_ for X in doc]\n",
    "\n",
    "\n",
    "# Produce a summary of reviews rates\n",
    "def review_rate_summary(df):\n",
    "    summary = pd.DataFrame(df['Review Rate'].value_counts()).reset_index()\n",
    "    summary = summary.rename(columns={'index': 'grade'})\n",
    "    summary['pct_grade'] = round(summary['Review Rate']/len(df),2)\n",
    "    summary = summary.sort_values(by = ['grade'], ascending= False)\n",
    "    return summary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Takes a list of tokens and returns POS tagging of tokens\n",
    "def return_POS_tokens(tok_list):\n",
    "    adv_list = []\n",
    "    verb_list = []\n",
    "    adj_list = []\n",
    "    noun_list = []\n",
    "    for token in tok_list:\n",
    "        category = nlp(token)[0].pos_\n",
    "        if category == 'ADV':\n",
    "            adv_list.append(token)\n",
    "        if category == 'VERB':\n",
    "            verb_list.append(token)\n",
    "        if category == 'ADJ':\n",
    "            adj_list.append(token)\n",
    "        if category == 'NOUN':\n",
    "            noun_list.append(token)\n",
    "        lists_dict = {'adv_list': adv_list,\n",
    "            'verb_list': verb_list,\n",
    "            'adj_list': adj_list,\n",
    "           'noun_list': noun_list}\n",
    "    return lists_dict\n",
    "\n",
    "\n",
    "def analyaze_nlp_reviews(df):\n",
    "    #common words lemmatized\n",
    "    common_words = ['Ãªtre', 'avoir']\n",
    "\n",
    "    input_sentence = concat_strings(df)\n",
    "    # remove punctuation\n",
    "    input_sentence = re.sub(r'[^\\w\\s]', \" \", input_sentence)\n",
    "    #Put to lower\n",
    "    input_sentence = input_sentence.lower()\n",
    "\n",
    "    #Return lemmatized tokens\n",
    "    lemmatized_tokens = lemmatize(input_sentence)\n",
    "\n",
    "    # Ste list of french stop words\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "\n",
    "    #Remove stop words\n",
    "    output = [w for w in lemmatized_tokens if not w in stop_words]\n",
    "    #Remove white spaces\n",
    "    output = [re.sub(r'[\\s*]', '', w) for w in output]\n",
    "    output = [w for w in output if not (w == '' or w in common_words)]\n",
    "    \n",
    "    unigram_most_common = Counter(output).most_common()\n",
    "    unigram_most_common = unigram_most_common[:20]\n",
    "    bigram_most_common = Counter(list(nltk.bigrams(output))).most_common()\n",
    "    bigram_most_common = bigram_most_common[:20]\n",
    "    trigram_most_common = Counter(list(nltk.ngrams(output,3))).most_common()[:20]\n",
    "    trigram_most_common = trigram_most_common[:20]\n",
    "\n",
    "    return {'output': output,\n",
    "        'unigram_most_common': unigram_most_common,\n",
    "            'bigram_most_common': bigram_most_common,\n",
    "            'trigram_most_common': trigram_most_common}\n",
    "\n",
    "\n",
    "\n",
    "# Main function to scrap data and return a dataframe\n",
    "def load_data(url, limit):\n",
    "    # Set up chromedriver\n",
    "    path = '/Users/manuel/Documents/GitHub/portfolio/Reviews project/chromedriver'\n",
    "    driver = webdriver.Chrome(service=Service(path))\n",
    "\n",
    "    # Go to reviews URL and click on refuse cookies\n",
    "    driver.get(url)\n",
    "    driver.find_element(By.XPATH,'/html/body/div[3]/div[3]/span/div/div/div/div[3]/div[1]/button[1]').click()\n",
    "    time.sleep(12)\n",
    "\n",
    "    # Get number of reviews\n",
    "    nb_reviews = driver.find_element(By.XPATH, '/html/body/span[2]/g-lightbox/div/div[2]/div[3]/span/div/div/div/div[1]/div[3]/div[1]/div/span/span').text\n",
    "    nb_reviews = int(nb_reviews.split(\" \")[0].replace('\\u202f', ''))\n",
    "\n",
    "    # Find scrollable element and scroll to load all reviews\n",
    "    scrollable_div = driver.find_element(By.XPATH,'/html/body/span[2]/g-lightbox/div/div[2]/div[3]/span/div/div/div/div[2]')\n",
    "\n",
    "    for i in range(min(find_nb_scroll(nb_reviews),limit)):\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', \n",
    "                    scrollable_div)\n",
    "        time.sleep(3)\n",
    "\n",
    "\n",
    "    # Get the html and find reviews object then apply function to get dataframe with relevant reviews information\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviews = response.find_all('div', class_ = 'WMbnJf vY6njf gws-localreviews__google-review')\n",
    "    review_summary = get_review_summary(reviews)\n",
    "\n",
    "\n",
    "    # Compute the estimated date of review based on date information\n",
    "    review_summary['Review Time Period'] = review_summary['Review Time Period'].map({'semaine': 7, 'semaines': 7, 'mois': 30, 'jour': 1, 'jours':1, 'heures': 0, 'heure': 0, 'ans': 365, 'an': 365})\n",
    "    review_summary['Estimated Review Date'] = review_summary['Review Time Amount'] * review_summary['Review Time Period']\n",
    "\n",
    "    today = datetime.today().strftime('%Y-%m-%d')\n",
    "    review_summary['Estimated Review Date'] = review_summary['Estimated Review Date'].apply(lambda x: pd.to_datetime(today) - timedelta(days=x))\n",
    "\n",
    "    review_summary = review_summary[['Estimated Review Date', 'Review Rate', 'Review Text']]\n",
    "\n",
    "    return review_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999eb39",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "66746688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimated Review Date</th>\n",
       "      <th>Review Rate</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>4</td>\n",
       "      <td>ExpÃ©rience Ã  vivre ! AprÃ¨s plusieurs tentative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-02</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>5</td>\n",
       "      <td>On ne fait plus leur renommÃ©e. Pas de rÃ©servat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>4</td>\n",
       "      <td>Bon resto pour manger des plats franÃ§ais simpl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Estimated Review Date  Review Rate  \\\n",
       "0            2022-06-02            4   \n",
       "1            2022-02-02            5   \n",
       "2            2022-08-31            5   \n",
       "3            2022-09-30            3   \n",
       "4            2022-08-01            4   \n",
       "\n",
       "                                         Review Text  \n",
       "0  ExpÃ©rience Ã  vivre ! AprÃ¨s plusieurs tentative...  \n",
       "1                                                     \n",
       "2  On ne fait plus leur renommÃ©e. Pas de rÃ©servat...  \n",
       "3                                                     \n",
       "4  Bon resto pour manger des plats franÃ§ais simpl...  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "start = time.time()\n",
    "url = 'https://www.google.com/search?q=bouillon+chartier&rlz=1C5CHFA_enFR941FR941&ei=BLleY82yGNmllwSqgJqAAQ&ved=0ahUKEwjNxI3VwYj7AhXZ0oUKHSqABhAQ4dUDCBA&uact=5&oq=bouillon+chartier&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIKCC4QxwEQrwEQQzIKCC4QxwEQrwEQQzIECAAQQzILCC4QgAQQxwEQrwEyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQ6CggAEEcQ1gQQsAM6BwgAELADEEM6EgguEMcBEK8BEMgDELADEEMYAToVCC4QxwEQrwEQ1AIQyAMQsAMQQxgBOgwILhDIAxCwAxBDGAE6BQguEIAESgQIQRgASgQIRhgBUMkDWIsKYI0LaAFwAXgAgAGTAYgBgweSAQMwLjeYAQCgAQHIARTAAQHaAQYIARABGAg&sclient=gws-wiz-serp#lrd=0x47e66e3e7dad1be3:0xf5848e4836f69968,1,,,'\n",
    "data = load_data(url, limit= 100)\n",
    "# Limit is the max number of scroll that will be performed (1 scroll = 10 reviews)\n",
    "end = time.time()\n",
    "\n",
    "# print the difference between start\n",
    "# and end time in milli. secs\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c2c817c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time of execution of above program is : 321.19885897636414 s\n"
     ]
    }
   ],
   "source": [
    "print(\"The time of execution of above program is :\",\n",
    "      (end-start), \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9e69af",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c76375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>Review Rate</th>\n",
       "      <th>pct_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade  Review Rate  pct_grade\n",
       "0      5           65       0.54\n",
       "1      4           35       0.29\n",
       "2      3           13       0.11\n",
       "3      2            4       0.03\n",
       "4      1            3       0.02"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_summary = review_rate_summary(data)\n",
    "rate_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9e4a13cd-f2d8-49d7-b1a2-433619bbc711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of reviews\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1f94da07-0470-41af-b44b-f9d5aadc5164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estimated Review Date    0\n",
       "Review Rate              0\n",
       "Review Text              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355eccab",
   "metadata": {},
   "source": [
    "# Overall analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eff73d",
   "metadata": {},
   "source": [
    "## Most recurrent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fa36df58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trÃ¨s', 74),\n",
       " ('bon', 45),\n",
       " ('prix', 44),\n",
       " ('serveur', 42),\n",
       " ('table', 37),\n",
       " ('plat', 34),\n",
       " ('faire', 32),\n",
       " ('tout', 32),\n",
       " ('cela', 28),\n",
       " ('attente', 27),\n",
       " ('peu', 26),\n",
       " ('manger', 22),\n",
       " ('plus', 22),\n",
       " ('si', 22),\n",
       " ('qualitÃ©', 21),\n",
       " ('service', 21),\n",
       " ('pouvoir', 20),\n",
       " ('2', 20),\n",
       " ('vraiment', 19),\n",
       " ('bien', 18)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_analysis = analyaze_nlp_reviews(data)\n",
    "nlp_analysis['unigram_most_common']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c632394",
   "metadata": {},
   "source": [
    "## Most recurrent bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f05ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('service', 'client'), 4),\n",
       " (('file', 'attente'), 3),\n",
       " (('chez', 'jour'), 3),\n",
       " (('salade', 'vouloir'), 2),\n",
       " (('intoxication', 'alimentaire'), 2),\n",
       " (('alimentaire', 'non'), 2),\n",
       " (('faire', 'queue'), 2),\n",
       " (('passer', 'commande'), 2),\n",
       " (('plus', 'rien'), 2),\n",
       " (('maÃ¯s', 'carotte'), 2),\n",
       " (('salade', '12'), 2),\n",
       " (('fruit', 'rouge'), 2),\n",
       " (('savoir', 'si'), 2),\n",
       " (('tant', 'pis'), 2),\n",
       " (('ingredient', 'frais'), 2),\n",
       " (('super', 'personnel'), 2),\n",
       " (('grand', 'amoureux'), 1),\n",
       " (('amoureux', 'chaÃ®ne'), 1),\n",
       " (('chaÃ®ne', 'pouvoir'), 1),\n",
       " (('pouvoir', 'dire'), 1)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_analysis['bigram_most_common']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57083192",
   "metadata": {},
   "source": [
    "## Most recurrent trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "486dd7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('intoxication', 'alimentaire', 'non'), 2),\n",
       " (('grand', 'amoureux', 'chaÃ®ne'), 1),\n",
       " (('amoureux', 'chaÃ®ne', 'pouvoir'), 1),\n",
       " (('chaÃ®ne', 'pouvoir', 'dire'), 1),\n",
       " (('pouvoir', 'dire', 'dernier'), 1),\n",
       " (('dire', 'dernier', 'fois'), 1),\n",
       " (('dernier', 'fois', 'mets'), 1),\n",
       " (('fois', 'mets', 'pied'), 1),\n",
       " (('mets', 'pied', 'encore'), 1),\n",
       " (('pied', 'encore', 'fois'), 1),\n",
       " (('encore', 'fois', 'pari'), 1),\n",
       " (('fois', 'pari', 'personnel'), 1),\n",
       " (('pari', 'personnel', 'envier'), 1),\n",
       " (('personnel', 'envier', 'travailler'), 1),\n",
       " (('envier', 'travailler', 'tomber'), 1),\n",
       " (('travailler', 'tomber', 'personne'), 1),\n",
       " (('tomber', 'personne', 'faire'), 1),\n",
       " (('personne', 'faire', 'salade'), 1),\n",
       " (('faire', 'salade', 'vouloir'), 1),\n",
       " (('salade', 'vouloir', 'absolument'), 1)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_analysis['trigram_most_common']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08341d0a-87ab-4919-a069-8c94aafac0af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ab9f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_by_word_category = return_POS_tokens(nlp_analysis['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e0e03b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plus', 14),\n",
       " ('trÃ¨s', 8),\n",
       " ('beaucoup', 8),\n",
       " ('bien', 7),\n",
       " ('client', 7),\n",
       " ('vraiment', 5),\n",
       " ('non', 4),\n",
       " ('donc', 4),\n",
       " ('peu', 4),\n",
       " ('encore', 3)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lists_by_word_category['adv_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "53942e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pouvoir', 8),\n",
       " ('payer', 8),\n",
       " ('ingrÃ©dient', 7),\n",
       " ('passer', 7),\n",
       " ('commande', 7),\n",
       " ('manger', 6),\n",
       " ('vouloir', 5),\n",
       " ('prendre', 5),\n",
       " ('restaurant', 5),\n",
       " ('dÃ©jeuner', 5)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lists_by_word_category['verb_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d5342e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('salade', 14),\n",
       " ('bon', 8),\n",
       " ('bureau', 3),\n",
       " ('sauce', 3),\n",
       " ('poulet', 3),\n",
       " ('file', 3),\n",
       " ('premier', 3),\n",
       " ('chaÃ®ne', 2),\n",
       " ('dernier', 2),\n",
       " ('veux', 2)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lists_by_word_category['adj_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "140e2ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jour', 8),\n",
       " ('frais', 7),\n",
       " ('service', 7),\n",
       " ('personnel', 6),\n",
       " ('jus', 5),\n",
       " ('fois', 4),\n",
       " ('boisson', 4),\n",
       " ('produit', 4),\n",
       " ('repas', 3),\n",
       " ('qualitÃ©', 3)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(lists_by_word_category['noun_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0dc449",
   "metadata": {},
   "source": [
    "# Bad reviews analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0ec2b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('table', 10),\n",
       " ('si', 5),\n",
       " ('manger', 4),\n",
       " ('tout', 4),\n",
       " ('repas', 3),\n",
       " ('sec', 3),\n",
       " ('serveur', 3),\n",
       " ('cadre', 3),\n",
       " ('sans', 3),\n",
       " ('cela', 3),\n",
       " ('oÃ¹', 3),\n",
       " ('prix', 3),\n",
       " ('trÃ¨s', 3),\n",
       " ('deux', 3),\n",
       " ('20min', 2),\n",
       " ('bouteille', 2),\n",
       " ('presque', 2),\n",
       " ('remplir', 2),\n",
       " ('mayonnaise', 2),\n",
       " ('fin', 2)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews = data[data['Review Rate'] <= 2]\n",
    "\n",
    "bad_reviews_analysis = analyaze_nlp_reviews(bad_reviews)\n",
    "bad_reviews_analysis['unigram_most_common']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "edf0ebe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('table', 'deux'), 2),\n",
       " (('table', 'quatre'), 2),\n",
       " (('experience', 'horrible'), 1),\n",
       " (('horrible', '20min'), 1),\n",
       " (('20min', 'ouvrir'), 1),\n",
       " (('ouvrir', 'bouteille'), 1),\n",
       " (('bouteille', 'rosÃ©'), 1),\n",
       " (('rosÃ©', 'temps'), 1),\n",
       " (('temps', 'manger'), 1),\n",
       " (('manger', 'entrÃ©e'), 1),\n",
       " (('entrÃ©e', 'presque'), 1),\n",
       " (('presque', 'finir'), 1),\n",
       " (('finir', 'repas'), 1),\n",
       " (('repas', 'repas'), 1),\n",
       " (('repas', 'pÃ¢te'), 1),\n",
       " (('pÃ¢te', 'lÃ©gume'), 1),\n",
       " (('lÃ©gume', 'remplir'), 1),\n",
       " (('remplir', 'huile'), 1),\n",
       " (('huile', 'demander'), 1),\n",
       " (('demander', 'mayonnaise'), 1)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews_analysis['bigram_most_common']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "264c0926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('experience', 'horrible', '20min'), 1),\n",
       " (('horrible', '20min', 'ouvrir'), 1),\n",
       " (('20min', 'ouvrir', 'bouteille'), 1),\n",
       " (('ouvrir', 'bouteille', 'rosÃ©'), 1),\n",
       " (('bouteille', 'rosÃ©', 'temps'), 1),\n",
       " (('rosÃ©', 'temps', 'manger'), 1),\n",
       " (('temps', 'manger', 'entrÃ©e'), 1),\n",
       " (('manger', 'entrÃ©e', 'presque'), 1),\n",
       " (('entrÃ©e', 'presque', 'finir'), 1),\n",
       " (('presque', 'finir', 'repas'), 1),\n",
       " (('finir', 'repas', 'repas'), 1),\n",
       " (('repas', 'repas', 'pÃ¢te'), 1),\n",
       " (('repas', 'pÃ¢te', 'lÃ©gume'), 1),\n",
       " (('pÃ¢te', 'lÃ©gume', 'remplir'), 1),\n",
       " (('lÃ©gume', 'remplir', 'huile'), 1),\n",
       " (('remplir', 'huile', 'demander'), 1),\n",
       " (('huile', 'demander', 'mayonnaise'), 1),\n",
       " (('demander', 'mayonnaise', 'grenaille'), 1),\n",
       " (('mayonnaise', 'grenaille', 'mayonnaise'), 1),\n",
       " (('grenaille', 'mayonnaise', 'dÃ©jÃ '), 1)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews_analysis['trigram_most_common']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "77dacf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_lists_by_word_category = return_POS_tokens(bad_reviews_analysis['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a58d05b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tout', 4),\n",
       " ('trÃ¨s', 3),\n",
       " ('presque', 2),\n",
       " ('client', 2),\n",
       " ('dÃ©jÃ ', 1),\n",
       " ('vite', 1),\n",
       " ('correctement', 1),\n",
       " ('alors', 1),\n",
       " ('allaient', 1),\n",
       " ('bouger', 1)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(bad_lists_by_word_category['adv_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "000df240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sec', 3),\n",
       " ('petit', 2),\n",
       " ('cher', 2),\n",
       " ('horrible', 1),\n",
       " ('grenaille', 1),\n",
       " ('servir', 1),\n",
       " ('sanitaire', 1),\n",
       " ('nouveau', 1),\n",
       " ('serveuse', 1),\n",
       " ('aimable', 1)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(bad_lists_by_word_category['adj_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "70c71e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('manger', 4),\n",
       " ('cadre', 3),\n",
       " ('remplir', 2),\n",
       " ('inconnu', 2),\n",
       " ('passer', 2),\n",
       " ('partager', 2),\n",
       " ('ouvrir', 1),\n",
       " ('rosÃ©', 1),\n",
       " ('finir', 1),\n",
       " ('demander', 1)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(bad_lists_by_word_category['verb_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "55199795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jour', 6),\n",
       " ('service', 5),\n",
       " ('boisson', 4),\n",
       " ('fois', 3),\n",
       " ('qualitÃ©', 3),\n",
       " ('date', 3),\n",
       " ('constat', 3),\n",
       " ('personnel', 2),\n",
       " ('problÃ¨me', 2),\n",
       " ('faim', 2)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(bad_lists_by_word_category['noun_list']).most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58052f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8528f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
